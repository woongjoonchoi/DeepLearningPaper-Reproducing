{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVm2diUOVrV1UBlKLfWtPR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import Caltech256 ,Caltech101 ,CIFAR100\n",
        "import os\n",
        "from PIL import Image\n",
        "from urllib.request import urlretrieve\n",
        "import requests\n",
        "import tarfile"
      ],
      "metadata": {
        "id": "Y8uDL3O9Nip2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "Sm3Wp8hN1zYw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "0AnFhMRnBmuy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5v1OM5551qSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# With square kernels and equal stride\n",
        "c = nn.Conv2d(16, 33, 3, stride=2)\n",
        "# non-square kernels and unequal stride and with padding\n",
        "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
        "d = nn.Conv2d(3,44,4)\n",
        "a=[]\n",
        "kk =[c,m]\n",
        "dd = [d]\n",
        "a += kk\n",
        "a += dd\n",
        "# li = nn.Sequential(*a)\n",
        "\n",
        "li = nn.ModuleList(a)\n",
        "\n",
        "# non-square kernels and unequal stride and with padding and dilation\n",
        "# m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
        "input = torch.ones(20, 16, 50, 100)\n",
        "output = m(input)\n",
        "\n"
      ],
      "metadata": {
        "id": "w_BAiLQ3Bkz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[[1, 2],\n",
        "                   [3, 4]],\n",
        "                  [[5, 6],\n",
        "                   [7, 8]]])\n",
        "torch.flatten(t)\n",
        "torch.flatten(t, start_dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ekup3kM0Qqbt",
        "outputId": "a191633c-267c-45b8-dbee-8bc5cc6bfbf3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3, 4],\n",
              "        [5, 6, 7, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1au_SwCQsID",
        "outputId": "ca6f27fa-6bdf-4cec-b137-d8ec4fad579d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tt = torch.ones(4,1000,1,1)\n",
        "\n",
        "tt=  torch.flatten(tt,start_dim = 1)"
      ],
      "metadata": {
        "id": "r3Z_ft7DvYm2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tt.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIukIPf_Qe-C",
        "outputId": "0c1e1335-2e33-4e97-a31f-5e1436762a74"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "li"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1UsThKfu0z0",
        "outputId": "f0799506-7d2f-4ef0-a078-ca378e1577ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
              "  (1): Conv2d(16, 33, kernel_size=(3, 5), stride=(2, 1), padding=(4, 2))\n",
              "  (2): Conv2d(3, 44, kernel_size=(4, 4), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djunLuqRBose",
        "outputId": "c9810059-e43c-4dd3-9ee1-a640b8e3cb7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 33, 28, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG model define"
      ],
      "metadata": {
        "id": "gklkOFYaZzK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Config_channels = {\n",
        "\"A\" : [64,\"M\" , 128,  \"M\"  , 256,256,\"M\" ,512,512 ,\"M\" , 512,512,\"M\"] ,\n",
        "\"A_lrn\" : [64,\"LRN\",\"M\" , 128,  \"M\"  , 256,256,\"M\" ,512,512 ,\"M\" , 512,512,\"M\"] ,\n",
        "\"B\" :[64,64,\"M\" , 128,128,  \"M\"  , 256,256,\"M\" ,512,512 ,\"M\" , 512,512,\"M\"]  ,\n",
        "\"C\" : [64,64,\"M\" , 128,128,  \"M\"  , 256,256,256,\"M\" ,512,512 ,512,\"M\" , 512,512,512,\"M\"] ,\n",
        "\"D\" :[64,64,\"M\" , 128,128,  \"M\"  , 256,256,256,\"M\" ,512,512 ,512,\"M\" , 512,512,512,\"M\"] ,\n",
        "\"E\" :[64,64,\"M\" , 128,128,  \"M\"  , 256,256,256,256,\"M\" ,512,512 ,512,512,\"M\" , 512,512,512,512,\"M\"]         ,\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "HZUTdQHU46GY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Config_kernel = {\n",
        "\"A\" : [3,2 , 3,  2  , 3,3,2 ,3,3 ,2 , 3,3,2] ,\n",
        "\"A_lrn\" : [3,2,2 , 3,  2  , 3,3,2 ,3,3 ,2 , 3,3,2] ,\n",
        "\"B\" :[3,3,2 , 3,3,  2  , 3,3,2 ,3,3 ,2 , 3,3,2]  ,\n",
        "\"C\" : [3,3,2 , 3,3,  2  , 3,3,1,2 ,3,3 ,1,2 , 3,3,1,2] ,\n",
        "\"D\" :[3,3,2 , 3,3,  2  , 3,3,3,2 ,3,3 ,3,2 , 3,3,3,2] ,\n",
        "\"E\" :[3,3,2 , 3,3,  2  , 3,3,3,3,2 ,3,3 ,3,3,2 , 3,3,3,3,2]         ,\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "hfv3t9rn6-5h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_feature_extractor(cfg_c,cfg_k):\n",
        "    feature_extract = []\n",
        "    in_channels = 3\n",
        "    i = 1\n",
        "    for  out_channels , kernel in zip(cfg_c,cfg_k) :\n",
        "        # print(f\"{i} th layer {out_channels} processing\")\n",
        "        if out_channels == \"M\" :\n",
        "            feature_extract += [nn.MaxPool2d(kernel,2) ]\n",
        "        elif out_channels == \"LRN\":\n",
        "            feature_extract += [nn.LocalResponseNorm(5,k=2) , nn.ReLU()]\n",
        "        else :\n",
        "            feature_extract+= [nn.Conv2d(in_channels,out_channels,kernel,stride = 1 , padding = 1) , nn.ReLU()]\n",
        "\n",
        "        if isinstance(out_channels,int) :   in_channels = out_channels\n",
        "        i+=1\n",
        "    return nn.Sequential(*feature_extract)\n"
      ],
      "metadata": {
        "id": "AXEMstbW9xeL"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_vgg(nn.Module) :\n",
        "    def __init__(self,version , num_classes):\n",
        "        conv_5_out_w ,conv_5_out_h = 7,7\n",
        "        conv_5_out_dim =512\n",
        "        conv_1_by_1_1_outchannel = 4096\n",
        "        conv_1_by_1_2_outchannel = 4096\n",
        "        # conv_1_by_1_3_outchannel = num_classes\n",
        "        super().__init__()\n",
        "        self.feature_extractor = make_feature_extractor(Config_channels[version] , Config_kernel[version])\n",
        "\n",
        "        self.output_layer = nn.Sequential(\n",
        "                             nn.Conv2d(conv_5_out_dim  ,conv_1_by_1_1_outchannel ,7) ,\n",
        "                             nn.ReLU(),\n",
        "                             nn.Dropout(),\n",
        "                             nn.Conv2d(conv_1_by_1_1_outchannel ,conv_1_by_1_2_outchannel,1 ) ,\n",
        "                             nn.ReLU(),\n",
        "                             nn.Dropout(),\n",
        "                             nn.Conv2d(conv_1_by_1_2_outchannel ,num_classes,1 )\n",
        "                             )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.output_layer(x)\n",
        "        x= self.avgpool(x)\n",
        "        x= torch.flatten(x,start_dim = 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "    #     pass\n",
        "\n"
      ],
      "metadata": {
        "id": "f1g6u9FW1p2G"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unit Test"
      ],
      "metadata": {
        "id": "yVLmRFfARAgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Parameter Unit Test"
      ],
      "metadata": {
        "id": "plcuwtnqRCOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_version = [\"A\",\"A_lrn\" , \"B\",\"C\",\"D\",\"E\"]"
      ],
      "metadata": {
        "id": "TAKCU4I2bgIi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_param_num  = [133,133,133,134,138,144]"
      ],
      "metadata": {
        "id": "A9MCs9f-b0v3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n"
      ],
      "metadata": {
        "id": "EWff_es2bOdr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parameter_num(model_parameters):\n",
        "    summed = sum([torch.numel(p) for p in model_parameters])\n",
        "    return summed"
      ],
      "metadata": {
        "id": "4nL8ne_4XaJz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for v ,number in zip(model_version ,model_param_num):\n",
        "    num_classes= 1000\n",
        "    model_test = Model_vgg(v,num_classes)\n",
        "    print(f\"{v} model processing\")\n",
        "    print(round(parameter_num(model_test.parameters()) / 1e+6))\n",
        "    assert(round(parameter_num(model_test.parameters()) / 1e+6) == number)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNdNPAFxREGh",
        "outputId": "eb617d48-002f-4ea3-d2c3-63e5cc38a466"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A model processing\n",
            "133\n",
            "A_lrn model processing\n",
            "133\n",
            "B model processing\n",
            "133\n",
            "C model processing\n",
            "134\n",
            "D model processing\n",
            "138\n",
            "E model processing\n",
            "144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model outputshape test"
      ],
      "metadata": {
        "id": "YwxFrrfDeT_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor = torch.rand((8,3,389,389))\n",
        "\n",
        "model_test = Model_vgg(\"A\" , 1000)"
      ],
      "metadata": {
        "id": "8NqTVpsSef7R"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_shape =[(9,3,400,400)  ,  (1,3,400,400)  ,(1,3,224,224)  , (8,3,389,389)]"
      ],
      "metadata": {
        "id": "CRd_wf7uhNO0"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sp in random_shape:\n",
        "    for v in model_version:\n",
        "        batch_size = sp[0]\n",
        "        num_classes = 1000\n",
        "        model_test = Model_vgg(v , num_classes)\n",
        "        random_tensor = torch.rand(sp)\n",
        "        output   = model_test(random_tensor)\n",
        "        print(f'{v} model output shape :{output.shape}')\n",
        "        assert tuple(output.shape) == (batch_size,num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meLqOBvEhbvF",
        "outputId": "fa2a46d9-e8b3-4a95-adac-2ba86b836de7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A model output shape :torch.Size([9, 1000])\n",
            "A_lrn model output shape :torch.Size([9, 1000])\n",
            "B model output shape :torch.Size([9, 1000])\n",
            "C model output shape :torch.Size([9, 1000])\n",
            "D model output shape :torch.Size([9, 1000])\n",
            "E model output shape :torch.Size([9, 1000])\n",
            "A model output shape :torch.Size([1, 1000])\n",
            "A_lrn model output shape :torch.Size([1, 1000])\n",
            "B model output shape :torch.Size([1, 1000])\n",
            "C model output shape :torch.Size([1, 1000])\n",
            "D model output shape :torch.Size([1, 1000])\n",
            "E model output shape :torch.Size([1, 1000])\n",
            "A model output shape :torch.Size([1, 1000])\n",
            "A_lrn model output shape :torch.Size([1, 1000])\n",
            "B model output shape :torch.Size([1, 1000])\n",
            "C model output shape :torch.Size([1, 1000])\n",
            "D model output shape :torch.Size([1, 1000])\n",
            "E model output shape :torch.Size([1, 1000])\n",
            "A model output shape :torch.Size([8, 1000])\n",
            "A_lrn model output shape :torch.Size([8, 1000])\n",
            "B model output shape :torch.Size([8, 1000])\n",
            "C model output shape :torch.Size([8, 1000])\n",
            "D model output shape :torch.Size([8, 1000])\n",
            "E model output shape :torch.Size([8, 1000])\n"
          ]
        }
      ]
    }
  ]
}